# References

1. [Papernot et al. “SoK: Towards the Science of Security and Privacy in Machine Learning”](https://arxiv.org/pdf/1611.03814.pdf)
    1.1 References numbered with \# in the slides correspond to the citation numbers from this paper.
1. [Chen et al. “Practical Attacks Against Graph-based Clustering”](https://arxiv.org/pdf/1708.09056.pdf)
1. [Meng et al. “MagNet: a Two-Pronged Defense against Adversarial Examples”](https://arxiv.org/pdf/1705.09064.pdf)
1. [Gu et al. “BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain”](https://arxiv.org/pdf/1708.06733.pdf) [code](https://github.com/Kooscii/BadNets/)
1. [Das et al. “Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression”](https://arxiv.org/pdf/1705.02900.pdf)
1. [Eykholt et al. “Robust Physical-World Attacks on Deep Learning Visual Classification”](https://arxiv.org/pdf/1707.08945.pdf)
1. [Zhang et al. “DolphinAttack: Inaudible Voice Commands”](https://arxiv.org/pdf/1708.09537.pdf)
1. [Cleverhans](https://github.com/tensorflow/cleverhans)
1. [Additional code](https://en.wikipedia.org/wiki/Adversarial_machine_learning#Software)
