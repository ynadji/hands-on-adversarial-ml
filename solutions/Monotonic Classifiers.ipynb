{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monotonic Classifiers\n",
    "\n",
    "Some classifiers should never \"flip-flop\" between classes. For example, consider the following classifier that labels system call traces from programs as being benign or malicious programs. No matter how many benign instructions are added to a malicious program, it should never trick the classifier into thinking it is benign.\n",
    "\n",
    "The classifier below takes sequences of system calls obtained from execution traces from malicious and benign programs. Treating each execution trace as a document, we extract a tf-idf[1] vector for feature extraction. Code below is provided that:\n",
    "1. Grabs ground truth traces\n",
    "1. Vectorizes them with tf-idf\n",
    "1. Performs 10-fold cross validation\n",
    "1. Trains a Logistic Regression model\n",
    "\n",
    "Your task as a malware author yourself, is to find direct and indirect ways to break this model so antivirus software cannot detect your code. Approach these tasks in three chunks:\n",
    "1. Manually manipulate a malicious feature vector such that the classifier mistakenly labels it malicious. If you successfully do this once, create a function that given a benign feature vector returns a new one that will be classified as benign.\n",
    "1. Identify features that, given your knowledge of what monotonic classifiers try to solve, could be used to \"flip\" a malicious program into benign one.\n",
    "1. Using the aforementioned features, write a function that transforms a malicious syscall trace (appending is fine) to be classified as benign.\n",
    "1. Modify the classifier so these features can no longer be used to \"flip\" a malicious trace. There's a quick'n'dirty way to do this, but more sophisticated[2] and robust[3] techniques exist if monotonicity is an important feature that your classifier needs.\n",
    "\n",
    "## References\n",
    "* [1] https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "* [2] https://arxiv.org/pdf/1804.03643.pdf\n",
    "* [3] https://www.slideshare.net/MSbluehat/bluehat-v17-detecting-compromise-on-windows-endpoints-with-osquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "import random\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## utils\n",
    "def rwalk(directory, pattern):\n",
    "    \"\"\"Recursively search \"directory\" for files that match the Unix shell-style\n",
    "    wildcard given by \"pattern\" (like '*.mp3'). Returns matches as a generator.\"\"\"\n",
    "    for root, dirnames, filenames in os.walk(directory):\n",
    "        for filename in fnmatch.filter(filenames, pattern):\n",
    "            yield os.path.join(root, filename)\n",
    "\n",
    "def gettraces(benignpath='../data/01-monotonic-classifiers/benign-traces',\n",
    "              malpath='../data/01-monotonic-classifiers/malicious-traces'):\n",
    "    return list(rwalk(malpath, '*.trace')), list(rwalk(benignpath, '*.trace'))\n",
    "\n",
    "def get_random_malicious_trace(malpath='../data/01-monotonic-classifiers/malicious-traces'):\n",
    "    \"\"\"Grab the text of a random malicious system call trace.\"\"\"\n",
    "    mal, _ = gettraces(malpath=malpath)\n",
    "    with open(random.choice(mal)) as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the TfidfVectorizer to vectorize ground truth\n",
    "\n",
    "The following extracts vectors from each benign and malicious execution trace and returns four values:\n",
    "1. `X`: the feature vectors\n",
    "1. `y`: the class labels\n",
    "1. `terms`: the list of labels (0 is benign, 1 is malicious)\n",
    "1. `vectorizer`: a TfidfVectorizer which is fit to the terms in the ground truth and can be used to fit new syscall traces with `vectorizer.transform([trace1, trace2, ..., traceN])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(featuredir='../data/01-monotonic-classifiers/feature-vectors'):\n",
    "    pos_traces, neg_traces = gettraces()\n",
    "    pos_y = [1 for _ in pos_traces]\n",
    "    neg_y = [0 for _ in neg_traces]\n",
    "    docs = [open(x).read() for x in pos_traces + neg_traces]\n",
    "    y = np.array(pos_y + neg_y)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(docs)\n",
    "    terms = np.asarray(vectorizer.get_feature_names())\n",
    "    return X, y, terms, vectorizer\n",
    "\n",
    "X, y, terms, vectorizer = vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x16 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 32000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ntcreateprocessex', 'ntcreatethreadex', 'ntcreateuserprocess',\n",
       "       'ntdisplaystring', 'ntdrawtext', 'ntmodifybootentry', 'ntopenfile',\n",
       "       'ntopenkeyex', 'ntopentimer', 'ntquerydirectoryfile', 'ntreadfile',\n",
       "       'ntsavekeyex', 'ntsettimerex', 'ntwritefile', 'regcreatekeyex',\n",
       "       'regsavekeyex'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _heatmap(crosstab):\n",
    "    plt.clf()\n",
    "    p = seaborn.heatmap(crosstab, square=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _cv(X, y, k, name, clf, csvname, modeldir=None, terms=None, resultdir=None):\n",
    "    print('## %s' % name)\n",
    "    print('### Cross Validation')\n",
    "    print('`%s`' % str(cross_val_score(clf, X, y, cv=k)))\n",
    "    print('### CV Confusion Matrix')\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=k)\n",
    "    print('```')\n",
    "    print(pd.crosstab(y, y_pred, rownames=['True'], colnames=['Predicted']))\n",
    "    print('```')\n",
    "    _heatmap(pd.crosstab(y, y_pred, rownames=['True'], colnames=['Predicted'],\n",
    "                         normalize='index'))\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## name\n",
      "### Cross Validation\n",
      "`[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]`\n",
      "### CV Confusion Matrix\n",
      "```\n",
      "Predicted     0     1\n",
      "True                 \n",
      "0          1000     0\n",
      "1             0  1000\n",
      "```\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = _cv(X, y, 10, 'name', LogisticRegression(solver='lbfgs'), 'foo.csv', modeldir='../work', terms=terms, resultdir='../work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.24482262,  2.24424061, -2.14186277, -2.13967196, -2.1405273 ,\n",
       "        2.24523331, -2.13965475, -2.13854639, -2.13845327, -2.1407568 ,\n",
       "       -2.14462209,  2.24613296,  2.24276795,  0.10771154,  2.24801507,\n",
       "        2.2431061 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ntcreateprocessex', 'ntcreatethreadex', 'ntcreateuserprocess',\n",
       "       'ntdisplaystring', 'ntdrawtext', 'ntmodifybootentry', 'ntopenfile',\n",
       "       'ntopenkeyex', 'ntopentimer', 'ntquerydirectoryfile', 'ntreadfile',\n",
       "       'ntsavekeyex', 'ntsettimerex', 'ntwritefile', 'regcreatekeyex',\n",
       "       'regsavekeyex'],\n",
       "      dtype='<U20')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Attack\n",
    "\n",
    "You (somehow) have direct access to the feature vectors. Don't ask how, celebrate! Traces are stored in `../data/01-monotonic-classifiers/{malicious,benign}-traces/`. I recommend writing a functions that returns a feature vector given the path of a trace, comparing benign and malicious vectors, and manually transforming a malicious vector to a benign vector. If you have time, write a function to perform this manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and Examine Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab trace, vectorize, classify, manipulate, re-classify\n",
    "def get_feature_vector(path, vectorizer):\n",
    "    with open(path) as f:\n",
    "        return vectorizer.transform([f.read()])\n",
    "mal_fv = get_feature_vector('../data/01-monotonic-classifiers/malicious-traces/0999.trace', vectorizer)\n",
    "ben_fv = get_feature_vector('../data/01-monotonic-classifiers/benign-traces/0999.trace', vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malicious\t\t\tbenign\n",
      "  (0, 15)\t0.334132498889\t  (0, 15)\t0.0417904620039\n",
      "  (0, 14)\t0.341169421524\t  (0, 14)\t0.0459695082042\n",
      "  (0, 13)\t0.398678065123\t  (0, 13)\t0.357830830908\n",
      "  (0, 12)\t0.325882313731\t  (0, 12)\t0.0397009389037\n",
      "  (0, 11)\t0.359125706867\t  (0, 11)\t0.0485814120795\n",
      "  (0, 10)\t0.0361552231914\t  (0, 10)\t0.32387608053\n",
      "  (0, 9)\t0.036397875696\t  (0, 9)\t0.344771311532\n",
      "  (0, 8)\t0.0327580881264\t  (0, 8)\t0.32909988828\n",
      "  (0, 7)\t0.0344566556589\t  (0, 7)\t0.32596560363\n",
      "  (0, 6)\t0.0356699181821\t  (0, 6)\t0.338502742231\n",
      "  (0, 5)\t0.341169421524\t  (0, 5)\t0.0438799851041\n",
      "  (0, 4)\t0.0334860456403\t  (0, 4)\t0.32701036518\n",
      "  (0, 3)\t0.0334860456403\t  (0, 3)\t0.316040368904\n",
      "  (0, 2)\t0.0334860456403\t  (0, 2)\t0.315517988129\n",
      "  (0, 1)\t0.3503902167\t  (0, 1)\t0.0407457004538\n",
      "  (0, 0)\t0.359368359372\t  (0, 0)\t0.0360442734783\n",
      "\n",
      "Malicious field larger than benign\n",
      "  (0, 0)\tTrue\n",
      "  (0, 1)\tTrue\n",
      "  (0, 5)\tTrue\n",
      "  (0, 11)\tTrue\n",
      "  (0, 12)\tTrue\n",
      "  (0, 13)\tTrue\n",
      "  (0, 14)\tTrue\n",
      "  (0, 15)\tTrue\n",
      "\n",
      "Malicious field smaller than benign\n",
      "  (0, 2)\tTrue\n",
      "  (0, 3)\tTrue\n",
      "  (0, 4)\tTrue\n",
      "  (0, 6)\tTrue\n",
      "  (0, 7)\tTrue\n",
      "  (0, 8)\tTrue\n",
      "  (0, 9)\tTrue\n",
      "  (0, 10)\tTrue\n"
     ]
    }
   ],
   "source": [
    "print('malicious\\t\\t\\tbenign')\n",
    "for mal, ben in zip(str(mal_fv).split('\\n'), str(ben_fv).split('\\n')):\n",
    "    print('%s\\t%s' % (mal, ben))\n",
    "print('\\nMalicious field larger than benign')\n",
    "print(mal_fv > ben_fv)\n",
    "print('\\nMalicious field smaller than benign')\n",
    "print(mal_fv < ben_fv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! Note the indices where the malicious field is smaller than benign. Let's increase these indices in a malicious vector and see if that causes the class labels to flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "def feature_vector_malicious_to_benign(fv):\n",
    "    \"\"\"This adds 1 to all indices in a malicious vector that are smaller than the benign vector to \n",
    "    transform it into a vector that will classify as benign.\"\"\"\n",
    "    #delta = np.array([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])\n",
    "    delta = np.array([0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
    "    return fv + delta\n",
    "print(clf.predict(fv))\n",
    "print(clf.predict(feature_vector_malicious_to_benign(fv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have successfully switched the label from malicious (1) to benign (0). Let's see if our function works on all the malicious samples now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1000})\n",
      "Counter({0: 1000})\n"
     ]
    }
   ],
   "source": [
    "maltraces, _ = gettraces()\n",
    "orig = []\n",
    "mutated = []\n",
    "for maltrace in maltraces:\n",
    "    fv = get_feature_vector(maltrace, vectorizer)\n",
    "    orig.append(clf.predict(fv))\n",
    "    mutated.append(clf.predict(feature_vector_malicious_to_benign(fv)))\n",
    "print(Counter([x[0] for x in orig]))\n",
    "print(Counter([x[0] for x in mutated]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huzzah! Our malware is now undetectable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indirect Attack Part 1 (Find terms)\n",
    "\n",
    "So we've made our malware undetectable (above), but we did so by directly manipulating the feature vector. This assumes a powerful and/or dedicated attacker and we're a bit lazy. How can we alter our malware's _behavior_ such that our malware is classified as benign software? Let's identify `terms` that are more likely to be associated with benign software than malicious software by finding _negative_ coefficients in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-2.1446220879737146, 'ntreadfile'),\n",
       " (-2.1418627669686741, 'ntcreateuserprocess'),\n",
       " (-2.1407567984612839, 'ntquerydirectoryfile'),\n",
       " (-2.1405272962289366, 'ntdrawtext'),\n",
       " (-2.1396719582510677, 'ntdisplaystring'),\n",
       " (-2.1396547495478844, 'ntopenfile'),\n",
       " (-2.1385463916610465, 'ntopenkeyex'),\n",
       " (-2.1384532744136897, 'ntopentimer'),\n",
       " (0.10771154443371365, 'ntwritefile'),\n",
       " (2.242767946060606, 'ntsettimerex'),\n",
       " (2.2431060978323187, 'regsavekeyex'),\n",
       " (2.2442406107176378, 'ntcreatethreadex'),\n",
       " (2.2448226246650846, 'ntcreateprocessex'),\n",
       " (2.2452333134082028, 'ntmodifybootentry'),\n",
       " (2.2461329578438232, 'ntsavekeyex'),\n",
       " (2.2480150712142488, 'regcreatekeyex')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(clf.coef_[0], terms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A-ha! These negatively weighted features will do nicely. This means we can simply append a lot of `ntreadfile` calls to our malware and it'll push the classification towards benign. Let's try it for one, random malicious trace. Consider that we can read as many files as we want in code and _not_ disrupt the malicious behavior that occurred earlier. Don't be shy about adding a lot of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = get_random_malicious_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = vectorizer.transform([foo])\n",
    "v2 = vectorizer.transform([foo + '\\n' + '\\n'.join(itertools.repeat('ntreadfile', 100000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! Looks like we can force the classification to flip by only indirectly manipulating the feature vector. Do you think this case is more or less reasonable than directly manipulating feature vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indirect Attack Part 2 (Adversarial Sample Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adversarial_sample(path):\n",
    "    with open(path) as f:\n",
    "        s = f.read()\n",
    "        numsyscalls = len(s.split())\n",
    "        s_benign = s + '\\n' + '\\n'.join(itertools.repeat('ntreadfile', numsyscalls))\n",
    "        return s, s_benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186656\n",
      "326543\n"
     ]
    }
   ],
   "source": [
    "s, s_benign = gen_adversarial_sample('../data/01-monotonic-classifiers/malicious-traces/0999.trace')\n",
    "print(len(s))\n",
    "print(len(s_benign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It works!\n",
    "clf.predict(vectorizer.transform([s, s_benign]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1000})\n",
      "Counter({0: 1000})\n"
     ]
    }
   ],
   "source": [
    "orig = []\n",
    "mutated = []\n",
    "for maltrace in maltraces:\n",
    "    mal, adv = gen_adversarial_sample(maltrace)\n",
    "    malvec = vectorizer.transform([mal])\n",
    "    advvec = vectorizer.transform([adv])\n",
    "    orig.append(clf.predict(malvec))\n",
    "    mutated.append(clf.predict(advvec))\n",
    "print(Counter([x[0] for x in orig]))\n",
    "print(Counter([x[0] for x in mutated]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only does it work on a single example, but it breaks everything we saw in the ground truth!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Classifier Monotonic\n",
    "\n",
    "A simple way to make a classifier monotonic for our purposes is to not allow attackers to abuse negative coefficient features. Add a vector to `clf.coef` such that there are no longer negative coefficients, and demonstrates this defeats your adversarial generation function from the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can accomplish this by:\n",
    "* Identify the index in `clf.coef_` for the feature you abused\n",
    "* Set its weight to `0.0`\n",
    "* Rerunning our classification examples from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_[0][clf.coef_.argmin()] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original malicious traces\n",
      "Counter({1: 1000})\n",
      "Adversarial malicious traces\n",
      "Counter({1: 1000})\n",
      "Original benign traces\n",
      "Counter({0: 1000})\n"
     ]
    }
   ],
   "source": [
    "maltraces, bentraces = gettraces()\n",
    "orig = []\n",
    "mutated = []\n",
    "benign = []\n",
    "for maltrace in maltraces:\n",
    "    mal, adv = gen_adversarial_sample(maltrace)\n",
    "    malvec = vectorizer.transform([mal])\n",
    "    advvec = vectorizer.transform([adv])\n",
    "    orig.append(clf.predict(malvec))\n",
    "    mutated.append(clf.predict(advvec))\n",
    "print('Original malicious traces')\n",
    "print(Counter([x[0] for x in orig]))\n",
    "print('Adversarial malicious traces')\n",
    "print(Counter([x[0] for x in mutated]))\n",
    "\n",
    "# What about the benign examples?\n",
    "for bentrace in bentraces:\n",
    "    benvec = get_feature_vector(bentrace, vectorizer)\n",
    "    benign.append(clf.predict(benvec))\n",
    "print('Original benign traces')\n",
    "print(Counter([x[0] for x in benign]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it works, but we more or less nullified the utility of the feature aside from its interactions with other variables when constructing the model. Sometimes keeping this is desirable, but it could suggest that this feature provides more drawbacks than benefits. This further demonstrates the importance of feature engineering: if the features are useful, but when known can be weaponized by attackers, perhaps it is better to sacrifice accuracy in order to have more resilient models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
